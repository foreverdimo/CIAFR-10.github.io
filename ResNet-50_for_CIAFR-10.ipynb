{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIAFR-10  image-classfication project\n",
    "\n",
    "Implemented by Yiyang Zhang 1800013111\n",
    "\n",
    "Using **ResNet-50** model\n",
    "\n",
    "About CIAFR-10 Datasets: \n",
    "[Datasets](https://www.cs.toronto.edu/~kriz/cifar.html )                         \n",
    "[References](https://en.wikipedia.org/wiki/CIFAR-10)\n",
    "\n",
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import required packages#\n",
    "import pickle\n",
    "import numpy as np \n",
    "import keras\n",
    "from keras.layers import Dense, Conv2D, BatchNormalization, Activation, Add, Input, Flatten, ZeroPadding2D, MaxPooling2D, AveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loading completed\n",
      "number of training examples = 50000\n",
      "number of test examples = 10000\n",
      "X_train shape: (50000, 32, 32, 3)\n",
      "Y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 32, 32, 3)\n",
      "Y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# If you have already downloaded the dataset and unpackaged it, make file_local true\n",
    "\n",
    "file_local = True\n",
    "\n",
    "#load dataset#\n",
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        dict = pickle.load(fo, encoding='bytes')\n",
    "    return dict\n",
    "\n",
    "def load_data():\n",
    "    \n",
    "    #load train data\n",
    "    X_train = []\n",
    "    Y_train = []\n",
    "    for i in range(1,6):\n",
    "        train_batch = unpickle(\"data_batch_\"+ str(i))\n",
    "        X_orig = train_batch[b\"data\"]\n",
    "        Y_orig = train_batch[b\"labels\"]\n",
    "        X_processed = X_orig.reshape((10000,3,32,32)).transpose(0,2,3,1).astype('float32')\n",
    "        Y_processed = to_categorical(np.array(Y_orig),10)\n",
    "        X_train.append(X_processed)\n",
    "        Y_train.append(Y_processed)\n",
    "    X_train = np.concatenate(X_train)\n",
    "    Y_train = np.concatenate(Y_train)\n",
    "    \n",
    "    #load test data\n",
    "    test_batch = unpickle(\"test_batch\")\n",
    "    X_orig = test_batch[b\"data\"]\n",
    "    Y_orig = test_batch[b\"labels\"]\n",
    "    X_test = X_orig.reshape((10000,3,32,32)).transpose(0,2,3,1).astype('float32')\n",
    "    Y_test = to_categorical(np.array(Y_orig),10)\n",
    "    \n",
    "    return X_train, Y_train, X_test, Y_test\n",
    "    \n",
    "if file_local :  \n",
    "    X_train, Y_train, X_test, Y_test = load_data()\n",
    "\n",
    "else :\n",
    "    (X_train, Y_train), (X_test, Y_test) = keras.datasets.cifar10.load_data()\n",
    "    Y_train = to_categorical(np.array(Y_train),10)\n",
    "    Y_test = to_categorical(np.array(Y_test),10)\n",
    "    \n",
    "    \n",
    "(M, n_H, n_W, n_C) = X_train.shape\n",
    "input_shape = (n_H,n_W,n_C)\n",
    "\n",
    "\n",
    "print (\"data loading completed\")\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build ResNet-50 Model\n",
    "\n",
    "The following figure describes in detail the architecture of this  network\n",
    "<img src=\"resnet_kiank.png\" style=\"width:850px;height:150px;\">\n",
    "\n",
    "And firstly We will impletemt convolutional residual block and identity residual block\n",
    "<img src=\"idblock3_kiank.png\" style=\"width:650px;height:150px;\">                       \n",
    "<caption><center> Identity block </center></caption>\n",
    "\n",
    "<img src=\"convblock_kiank.png\" style=\"width:650px;height:150px;\">                       \n",
    "<caption><center> convolutional block </center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_block(X, f, kernel_channels ,activation = 'relu'):\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    F1,F2,F3 = kernel_channels\n",
    "\n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "def conv_block(X, f, kernel_channels, strides, activation = 'relu'):\n",
    "    \n",
    "    X_shortcut = X\n",
    "    \n",
    "    F1,F2,F3 = kernel_channels\n",
    "    \n",
    "    X = Conv2D(filters = F1, kernel_size = (1, 1), strides = (strides,strides), padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation(activation)(X)\n",
    "\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "\n",
    "    X_shortcut = Conv2D(filters = F3, kernel_size = (1, 1), strides = (strides,strides), padding = 'valid')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut )\n",
    "\n",
    "    X = Add()([X,X_shortcut])\n",
    "    X = Activation(activation)(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def ResNet50(Input_shape = (32, 32, 3), classes = 10):\n",
    "    \n",
    "    X_input = Input(Input_shape)\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "    \n",
    "    #stage 1\n",
    "    X = Conv2D(64, (3, 3), strides = (2, 2), padding = 'valid')(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "    \n",
    "    #stage 2\n",
    "    \n",
    "    X = conv_block(X , 3 , kernel_channels = [64, 64, 256], strides = 1)\n",
    "    X = id_block(X, 3, kernel_channels = [64, 64, 256])\n",
    "    X = id_block(X, 3, kernel_channels = [64, 64, 256])\n",
    "    \n",
    "    #stage 3\n",
    "    \n",
    "    X = conv_block(X, 3, kernel_channels = [128, 128, 512], strides = 1)\n",
    "    X = id_block(X, 3, kernel_channels = [128, 128, 512])\n",
    "    X = id_block(X, 3, kernel_channels = [128, 128, 512])\n",
    "    X = id_block(X, 3, kernel_channels = [128, 128, 512])\n",
    "    \n",
    "    #stage 4\n",
    "    \n",
    "    X = conv_block(X, 3, kernel_channels = [256, 256, 1024], strides = 2)\n",
    "    X = id_block(X, 3, kernel_channels = [256, 256, 1024])\n",
    "    X = id_block(X, 3, kernel_channels = [256, 256, 1024])\n",
    "    X = id_block(X, 3, kernel_channels = [256, 256, 1024])\n",
    "    X = id_block(X, 3, kernel_channels = [256, 256, 1024])\n",
    "    X = id_block(X, 3, kernel_channels = [256, 256, 1024])\n",
    "    \n",
    "    #stage 5\n",
    "    \n",
    "    X = conv_block(X, 3, kernel_channels = [512, 512, 2048], strides = 2)\n",
    "    X = id_block(X, 3, kernel_channels = [512, 512, 2048])\n",
    "    X = id_block(X, 3, kernel_channels = [512, 512, 2048])\n",
    "    \n",
    "    X = AveragePooling2D(pool_size = (2, 2))(X)\n",
    "    \n",
    "    X = Flatten()(X)\n",
    "    X = Dense(1024, activation='relu')(X)\n",
    "    X = Dense(classes, activation='softmax')(X)\n",
    "    \n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name='ResNet50')\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50000/50000 [==============================] - 68s 1ms/step - loss: 1.9772 - accuracy: 0.3443\n",
      "Epoch 2/100\n",
      "50000/50000 [==============================] - 53s 1ms/step - loss: 1.1931 - accuracy: 0.5727\n",
      "Epoch 3/100\n",
      "50000/50000 [==============================] - 55s 1ms/step - loss: 0.9500 - accuracy: 0.6651\n",
      "Epoch 4/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.7792 - accuracy: 0.7263\n",
      "Epoch 5/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.6482 - accuracy: 0.7716\n",
      "Epoch 6/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.5553 - accuracy: 0.8049\n",
      "Epoch 7/100\n",
      "50000/50000 [==============================] - 58s 1ms/step - loss: 0.4638 - accuracy: 0.8374\n",
      "Epoch 8/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3841 - accuracy: 0.8646\n",
      "Epoch 9/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.3250 - accuracy: 0.8863\n",
      "Epoch 10/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.2840 - accuracy: 0.9006\n",
      "Epoch 11/100\n",
      "50000/50000 [==============================] - 62s 1ms/step - loss: 0.2384 - accuracy: 0.9170\n",
      "Epoch 12/100\n",
      "50000/50000 [==============================] - 61s 1ms/step - loss: 0.2082 - accuracy: 0.9268\n",
      "Epoch 13/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1871 - accuracy: 0.9358\n",
      "Epoch 14/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.1527 - accuracy: 0.9460\n",
      "Epoch 15/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.1451 - accuracy: 0.9491\n",
      "Epoch 16/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.1379 - accuracy: 0.9512\n",
      "Epoch 17/100\n",
      "50000/50000 [==============================] - 57s 1ms/step - loss: 0.1232 - accuracy: 0.9564\n",
      "Epoch 18/100\n",
      "50000/50000 [==============================] - 63s 1ms/step - loss: 0.1182 - accuracy: 0.9597\n",
      "Epoch 19/100\n",
      "50000/50000 [==============================] - 59s 1ms/step - loss: 0.1134 - accuracy: 0.9597\n",
      "Epoch 20/100\n",
      "50000/50000 [==============================] - 60s 1ms/step - loss: 0.0923 - accuracy: 0.9684\n",
      "Epoch 21/100\n",
      "50000/50000 [==============================] - 56s 1ms/step - loss: 0.0923 - accuracy: 0.9685\n",
      "Epoch 22/100\n",
      " 5888/50000 [==>...........................] - ETA: 49s - loss: 0.1463 - accuracy: 0.9492"
     ]
    }
   ],
   "source": [
    "model = ResNet50(input_shape, classes= 10)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, Y_train, epochs = 100, batch_size = 256)\n",
    "\n",
    "preds = model.evaluate(X_test, Y_test)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
